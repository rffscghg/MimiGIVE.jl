{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explanations and Post-Processing Scripts for MimiGIVE.jl\n",
    "\n",
    "The following notebook will detail the different data files in the _data_ folder including their source and any post-processing done to obtain the files directly imported by the `MimiGIVE` API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. General Model Data\n",
    "\n",
    "**Dimension_countries.csv**\n",
    "\n",
    "This file holds the list of countries, by ISO3 code, that serve as the `country` dimensions for this model.  By necessity of obtaining country-level GDP and Population, this list must be a subset of the countries available to be provided by the `Socioeconomics` component utilized, which may be either from [MimiSSPs](https://github.com/anthofflab/MimiSSPs.jl) or [MimiRFFSPs](https://github.com/rffscghg/MimiRFFSPs.jl). 184 countries are available in Benveniste et al., 2020, and are subset for components which do not have calculations available for all countries (CIAM calculates for 145 of the total countries).\n",
    "\n",
    "Further information on country names, numeric codes, and alphanumeric codes for the ISO3 dataset can be found [here](https://en.wikipedia.org/wiki/ISO_3166-1) on Wikipedia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mortality Components\n",
    "\n",
    "### 2a. General\n",
    "\n",
    "**Mortality_cdf_spp_country_extensions.csv** and **Mortality_cdf_ssp_country_extensions_annual.csv**\n",
    "\n",
    "_Mortality_cdf_spp_country_extensions.csv_ was recieved from Dr. David Smith (EPA) on October 8, 2021, and holds the SSP mortality data with extensions out to 2300. The raw data out to 2100 are stored at the [Wittgenstein Centre](https://nam02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fdataexplorer.wittgensteincentre.org%2Fwcde-v2%2F&data=04%7C01%7Crennert%40rff.org%7C96cba6d9096647c0159f08d98a001bc0%7Cb29f848db9144be4ad1f89bdbdb8030a%7C0%7C1%7C637692555407649003%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&sdata=Ji7h6eHB2mHnEaCco3RvbvpDP1j4PMcNHdRa2pdgMYQ%3D&reserved=0) and can be accessed in R by using the [wcde](https://guyabel.github.io/wcde/) package. Samir KC and Wolfgang Lutz, the two original authors of the population projections, are jointly appointed to IIASA and to the Wittgenstein Center. This database only has data for SSPs 1 through 3. Based on [KC and Lutz et al., 2017](https://www.sciencedirect.com/science/article/pii/S0959378014001095)it appears that the mortality assumptions are similar for SSP2 and SPP4 and for SSP1 and SSP5, this assumption is adopted and SSP1 is used as a proxy for SSP5 and SSP2 as a proxy for SSP4, for this variable. For the projections, the crude death rate post-2100 for each country converging towards the 2100 world crude death (by SSP). All countries reach the 2100 world crude death rate in 2300. Data exists for 200 countries. Units for the crude death rate are number of deaths occurring over a five-year period (period ends on the year in the year column) per 1,000 total population.\n",
    "\n",
    "Post processing of these data for our use is as follows, and produces _Mortality_cdf_ssp_country_extensions_annual.csv_. To downscale these data from five year increments to annual deaths per 1000 people, the interval value is divided value by the population in the middle of the interval, multiply by 1000 (people), and divide by the time interval (5 years). Note that because of this recommended post processing step this needs to be done ahead of time for each potential population scenario that will be employed, and adjusted if population scenarios change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, Query, CSVFiles\n",
    "\n",
    "mortality_countries = load(joinpath(@__DIR__, \"..\", \"data\", \"Dimension_countries.csv\")) |> DataFrame\n",
    "time_interval = 5\n",
    "\n",
    "raw_df = load(joinpath(@__DIR__, \"..\", \"data\", \"Mortality_cdr_spp_country_extensions.csv\")) |> \n",
    "    DataFrame |>\n",
    "    @filter(_.alpha3 in mortality_countries.CountryISO) |>\n",
    "    DataFrame\n",
    "\n",
    "# check that we have all the countries\n",
    "sort(unique(raw_df.alpha3)) == sort(mortality_countries.CountryISO) ? nothing : error(\"Baseline mortality data needs to include all mortality countries used in model.\")\n",
    "\n",
    "# interpolate each country for each SSP\n",
    "annual_df = DataFrame(:year => [], :ISO => [], :scenario => [], :cdf => [])\n",
    "for SSP in unique(raw_df.scenario_abb)\n",
    "    for country in unique(raw_df.alpha3)\n",
    "\n",
    "        filtered_df = raw_df |> @filter(_.scenario_abb == SSP && _.alpha3 == country) |> DataFrame\n",
    "        population = load(joinpath(@__DIR__, \"..\", \"data\", \"Benveniste_SSPs\", \"Benveniste_$SSP.csv\")) |> \n",
    "            DataFrame |>\n",
    "            @filter(_.country == country) |> \n",
    "            DataFrame\n",
    "        \n",
    "        for year in unique(filtered_df.year)\n",
    "            \n",
    "            # get the end of interval cdr value\n",
    "            cdr = ((filtered_df |> @filter(_.year == year) |> DataFrame).cdr)[1]\n",
    "            # get population in the years of this time period for scaling\n",
    "            pop_interval = (population |> @filter(_.year in collect(year-4:year)) |> DataFrame).pop\n",
    "            # get the deaths per five year period, divide by population in center year, and scale to 1000\n",
    "            deaths_in_interval = sum(pop_interval/1000) * cdr\n",
    "            # get annual cdr for the interval\n",
    "            cdf_annual = ((deaths_in_interval/pop_interval[3]) / 5) * 1000\n",
    "            \n",
    "            append!(annual_df, DataFrame(\n",
    "                :year => collect(year - 4:year),\n",
    "                :ISO => fill(country, 5),\n",
    "                :scenario => fill(SSP, 5),\n",
    "                :cdf => fill(cdf_annual, 5)\n",
    "            ))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "annual_df |> save(joinpath(@__DIR__, \"..\", \"data\", \"Mortality_cdr_spp_country_extensions_annual.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Cromar Mortality Component\n",
    "\n",
    "**Dimension_cromar_mortality_regions.csv**\n",
    "\n",
    "This file holds the list of regions used for the Cromar Mortality damage functions, as found in Cromar et al. and that serve as the `cromar_regions` dimension for this model.\n",
    "\n",
    "**CromarMortality_damages_coefficients.csv**\n",
    "\n",
    "This file holds the coefficients received from Cromar et al. for the damage function.\n",
    "\n",
    "**Mapping_countries_to_cromar_mortality_regions.csv**\n",
    "\n",
    "This file holds the mapping from the `country` dimensoin in the model to the `cromar_mortality_regions` dimension in the model. This was done by mapping the GCAM regions used by the `gcam_regions` to the `cromar_regions` as follows and then using the country lists from GCAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agriculture Component\n",
    "\n",
    "**Dimension_fund_regions.csv**\n",
    "\n",
    "This file holds the list of codes for the [FUND](https://github.com/fund-model/MimiFUND.jl) regions that serve as the `fund_regions` dimensions for this model.\n",
    "\n",
    "**Mapping_countries_to_fund_regions.xlsx**\n",
    "\n",
    "This workbook holds the working lookups and crosswalks to move between various subsets of countries and FUND regions, including country names in addition to ISO3 codes etc.  It is the source for the following file.\n",
    "\n",
    "**Mapping_countries_to_fund_regions.csv**\n",
    "\n",
    "This file holds the mapping from the `country` dimension in the model to the `fund_regions` dimension in the model.  It is pulled directly from the _BENVENISTE_ tab in the workbook above, _Mapping_countries_to_fund_regions.xlsx_.\n",
    "\n",
    "**Benveniste_SSPs/Benveniste_SSPX.csv** and **Benveniste_SSPs/Agriculture_1990vals.csv**\n",
    "\n",
    "The _data/Benveniste_SSPs_ folder holds copies of the the Benveniste et al., 2020 data used in the `MimiSSPs` component for the setting of `SSPmodel = \"Benveniste\"` filtered for the year 1990.  This is processed into regional values for the year 1990 to provide for the `pop90` and `gdp90` parameters for the `Agriculture` component using the script below.  Notice this uses _ALL_ 184 countries, and could be generalized to accomodate a different countries list if needed in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, Query, CSVFiles\n",
    "\n",
    "input_output_mapping = load(joinpath(@__DIR__, \"..\", \"data\", \"Mapping_countries_to_fund_regions.csv\")) |> DataFrame |> @select(:ISO3, :fundregion) |> DataFrame\n",
    "fund_regions = load(joinpath(@__DIR__, \"..\", \"data\", \"Dimension_fund_regions.csv\")) |> DataFrame \n",
    "\n",
    "df_1990 = DataFrame(:SSP => [], :fund_region => [], :pop => [], :gdp => [])\n",
    "\n",
    "for SSP in [\"SSP1\", \"SSP2\", \"SSP3\", \"SSP4\", \"SSP5\"]\n",
    "    df_SSP = load(joinpath(@__DIR__, \"..\", \"data\", \"Benveniste_SSPs\", \"Benveniste_$SSP.csv\")) |> \n",
    "        DataFrame |>\n",
    "        @filter(_.year == 1990) |>\n",
    "        DataFrame\n",
    "\n",
    "    for region in fund_regions.fund_region\n",
    "        countries = (input_output_mapping |> @filter(_.fundregion == region) |> DataFrame |> @select(:ISO3) |> DataFrame |> Matrix)[:]\n",
    "        df_SSP_region = df_SSP |> @filter(_.country in countries) |> DataFrame\n",
    "\n",
    "        if region == \"SEA\" # note that TWN has a missing GDP value until 2015 use value from imf.org (\"Report for Selected Countries and Subjects\". www.imf.org. Archived from the original on 31 July 2020. Retrieved 2 May 2020.)\n",
    "            TWN_row = findfirst(i -> i == \"TWN\", df_SSP_region.country)\n",
    "            df_SSP_region.gdp[TWN_row] = 205 * 1.4 # $2020 to $2005\n",
    "        end\n",
    "\n",
    "        append!(df_1990, DataFrame(:SSP => SSP, :fund_region => region, :pop => sum(df_SSP_region.pop), :gdp => sum(df_SSP_region.gdp)))\n",
    "    end\n",
    "end\n",
    "df_1990 |> save(joinpath(@__DIR__, \"..\", \"data\", \"Benveniste_SSPs\", \"Agriculture_1990vals.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sea Level Rise Component (CIAM)\n",
    "**Dimension_ciam_countries.csv**\n",
    "\n",
    "This file holds the list of countries, by ISO3 code, that serve as the `ciam_country` dimensions for this model and are a subset of what is used in [MimiCIAM.jl](https://github.com/raddleverse/MimiCIAM.jl), representing only the 145 countries which overlap with our `country` dimension. \n",
    "\n",
    "**CIAM/diva_segment_latlon.csv**\n",
    "\n",
    "This file holds metadata for the segments used in CIAM and was pulled directly frim the [CIAM repository](https://github.com/raddleverse/MimiCIAM.jl/tree/master/data), and subsequently the `rgn` ISO3 code was joined based on the MimiCIAM key file `xsc.csv`, for all available segments.\n",
    "\n",
    "**CIAM/FINGERPRINTS_SLANGEN_Bakker.nc**\n",
    "\n",
    "This file holds the BRICK original fingerprints from the [BRICK repository](https://github.com/scrim-network/BRICK/raw/master/fingerprints) for all available segments.\n",
    "\n",
    "**CIAM/segment_fingerprints.csv**\n",
    "\n",
    "This file is created using scripts in `src/utils/lsl_downscaling.jl` as called below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MimiGIVE\n",
    "\n",
    "MimiGIVE.get_segment_fingerprints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**CIAM/xsc_ciam_countries.csv**\n",
    "\n",
    "This file contains metadata about the segments, including seg (segment name), rgn (region of segment ID), greenland (in or out), island (yes or no), segID (ID of segment), rgnID (ID of region) **that are used in this model**.  This will perfectly match with the `ciam_country` dimension, and does not necessarily thus include all countries available within `MimiCIAM.jl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Climate Components - FAIR v1.6.2\n",
    "\n",
    "**FAIR_ar6/AR6_emissions_sspXX_1750_2300.csv**\n",
    "\n",
    "These data are obtained directly from [MimiFAIRv1_6_2.jl](https://github.com/FrankErrickson/MimiFAIRv1_6_2.jl) and represent the emissions trajectories used by AR6.\n",
    "\n",
    "**FAIR_mcs/fair-1.6.2-wg3-params.json.zip**\n",
    "\n",
    "This file is obtained directly from the [MimiFAIRv1_6_2.jl](https://github.com/FrankErrickson/MimiFAIRv1_6_2.jl) which in turn downloaded [from Zenodo](https://zenodo.org/record/5513022#.YWPzVS2cYW9) and represents the constrained parameter set used in AR6.  Post-processing of these data is as follows, to be used in the Monte Carlo Simulation. Processing can be found in the script _process_fair_mcs_params.jl_, which will first require unzipping _fair-1.6.2-wg3-params.json.zip_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(joinpath(@__DIR__, \"..\", \"utils\", \"process_fair_mcs_params.jl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Energy Component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**energy_damages_gcam_region_coefficients.csv**\n",
    "\n",
    "This file holds the coefficients used in the energy damage function, with one coefficient per GCAM `gcam_energy_regions` as defined in the following file.\n",
    "\n",
    "**Dimension_gcam_energy_regions.csv**\n",
    "\n",
    "This file holds the names of the GCAM energy regions.\n",
    "\n",
    "**Mapping_countries_to_gcam_energy_regions.csv**\n",
    "\n",
    "This file maps the 184 model `countries` to the 12 GCAM `gcam_energy_regions`, noting that the following mappings are made manually as they were not explicitly included in the input data:\n",
    "\n",
    "```\n",
    "HKG\t Hong Kong    China\n",
    "MAC\t Macao\t      China\n",
    "MMR\t Burma\t      Other_Asia\n",
    "PRI\t Puerto Rico  USA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. BRICK Sea Level Rise\n",
    "\n",
    "**BRICK_posterior_parameters_10k.csv**\n",
    "\n",
    "This file holds 10,000 sets of posterior parameters for BRICK uncertainty post-calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Constraints\n",
    "\n",
    "### Imposing Constraints on the RFF-SPs for use in MCS\n",
    "\n",
    "In [Rennert et al. 2022](https://www.brookings.edu/bpea-articles/the-social-cost-of-carbon/), one constraint that is imposed as a sensitivity<sup>1</sup> is to drop trials where global average income per capita in 2300 falls in the 1% tails of distribution. This results in 9,800 remaining trials (dropping 200). The _rffsps_1ct_trimmed.csv_ file holds this constrained sample of 9,800 trial IDs.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "1. The motivation behind this sensitivity is described in [the paper](https://www.brookings.edu/bpea-articles/the-social-cost-of-carbon/) on page 36 as: \"The second row of Table 1 highlights this greater stability under stochastic discounting by showing a sensitivity case in which we drop the top and bottom 1 percent of the global average income trajectories\" along with footnote number 34: \"Specifically, we drop the draws with global average GDP per capita in 2300 in the top 1percent and bottom 1 percent of draws, before taking the average SCC.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleans RFF-SPs, aggregates to global, and trims outliers from upper and lower 1% \n",
    "## of global average income distribtion in the year 2300\n",
    " \n",
    "##########################\n",
    "#################  library\n",
    "##########################\n",
    "  \n",
    "## Clear worksace\n",
    "rm(list = ls())\n",
    "gc()\n",
    "  \n",
    "## This function will check if a package is installed, and if not, install it\n",
    "list.of.packages <- c('magrittr','tidyverse','arrow','zoo')\n",
    "new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]\n",
    "if(length(new.packages)) install.packages(new.packages, repos = \"http://cran.rstudio.com/\")\n",
    "lapply(list.of.packages, library, character.only = TRUE)\n",
    "  \n",
    "##########################\n",
    "##################### data\n",
    "##########################\n",
    "  \n",
    "## inflate rff data\n",
    "pricelevel_2005_to_2020 = 113.648/87.504 # 2005$ to 2020$, recovered 9/16/2021 from: https://apps.bea.gov/iTable/iTable.cfm?reqid=19&step=3&isuri=1&select_all_years=0&nipa_table_list=13&series=a&first_year=2015&last_year=2020&scale=-99&categories=survey&thetable=\n",
    "rffsp_inflator = (87.504/98.164)*pricelevel_2005_to_2020 #rff-sps are in 2011$. Convert to 2005$ then to $2020$, from https://github.com/rffscghg/MimiRFFSPs.jl/blob/9f78ab45e74040134152612eb6c31327c6d1543a/src/components/SPs.jl#L5\n",
    "  \n",
    "## list of files\n",
    "files <- list.files('.julia/datadeps/rffsps_v3/pop_income', full.names=T)\n",
    "  \n",
    "## blank data\n",
    "data = tibble()\n",
    "\n",
    "## start loop\n",
    "for (i in 1:length(files)){\n",
    "\n",
    "    print(paste('Reading file number ', i, ' of ', length(files)))\n",
    "  \n",
    "    file = files[i]\n",
    "    rffsp.id = str_sub(str_split(file,pat='/')[[1]][8],22,-9)\n",
    "\n",
    "    rff = read_feather(file) %>% \n",
    "      rename_all(tolower) %>% \n",
    "      group_by(country) %>%\n",
    "      complete(year = seq(first(year), last(year))) %>% \n",
    "      mutate(pop = exp(na.approx(log(pop))),\n",
    "             gdp = exp(na.approx(log(gdp)))) %>% \n",
    "      ungroup() %>% \n",
    "      select(-country) %>% \n",
    "      group_by(year) %>% \n",
    "      summarise_all(sum, na.rm = TRUE) %>% \n",
    "      mutate(pop      = pop/1e6,\n",
    "             gdp      = gdp/1e6*rffsp_inflator,\n",
    "             ypc      = gdp/pop,\n",
    "             ypc.gr   = log(ypc/lag(ypc,default = ypc[1])),\n",
    "             rffsp.id = rffsp.id) %>% \n",
    "      relocate(rffsp.id, year, gdp, pop, ypc, ypc.gr)\n",
    "\n",
    "    data = bind_rows(data, rff)\n",
    "    \n",
    "    rm(rff)\n",
    "    gc()\n",
    "\n",
    "} \n",
    "  \n",
    "## export global untrimmed aggregates\n",
    "data %>% write_csv(.,'RFFModel/data/rffsp_global.csv')\n",
    "\n",
    "## \n",
    "rff = read_csv('data/rff/rffsp_global.csv') %>% filter(year == 2300) %>% rename(trialnum = rffsp.id) %>% select(trialnum, ypc) %>% arrange(trialnum)\n",
    "\n",
    "## trim outliers based on ypc in 2300\n",
    "rff_trimmed = rff %>% filter(ypc >= quantile(ypc,0.01) & ypc <= quantile(ypc,0.99))\n",
    "\n",
    "## check outliers\n",
    "rff_outliers = rff %>% filter(ypc < quantile(ypc,0.01) | ypc > quantile(ypc,0.99))\n",
    "\n",
    "## export outliers for use in mcs\n",
    "rff_trimmed %>% select(trialnum) %>% arrange(trialnum) %>% write_csv('RFFModel/data/rffsp_1pct_trimmed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.6",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
